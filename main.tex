% Written by Daina Chiba (daina.chiba@gmail.com).
% It was mostly copied from two poster style files:
% beamerthemeI6pd2.sty written by
%	 	Philippe Dreuw <dreuw@cs.rwth-aachen.de> and 
% 		Thomas Deselaers <deselaers@cs.rwth-aachen.de>
% and beamerthemeconfposter.sty written by
%     Nathaniel Johnston (nathaniel@nathanieljohnston.com)
%		http://www.nathanieljohnston.com/2009/08/latex-poster-template/
% 
% Modified for UvA by
% Maarten de Rijke, April 2014
%
%---------------------------------------------------------------------------------------------------% 
% Preamble
% ---------------------------------------------------------------------------------------------------% 
\documentclass[final]{beamer}
\usepackage[orientation=landscape,size=a0,scale=1.2,debug]{beamerposter}
\mode<presentation>{\usetheme{UvAPoster}}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsthm, amssymb, latexsym}
\usepackage{exscale}
\usepackage{caption}

\usepackage{array,booktabs,tabularx}
\newcolumntype{Z}{>{\centering\arraybackslash}X} % centered tabularx columns

% comment 
\newcommand{\comment}[1]{}

% (relative) path to the figures
\graphicspath{{figs/}}

\newlength{\columnheight}
\setlength{\columnheight}{105cm}
\newlength{\sepwid}
\newlength{\onecolwid}
\newlength{\twocolwid}
\newlength{\threecolwid}
\setlength{\sepwid}{0.024\paperwidth}
\setlength{\onecolwid}{0.24\paperwidth}
\setlength{\twocolwid}{0.4\paperwidth}
\setlength{\threecolwid}{0.19\paperwidth}

\setbeamertemplate{bibliography item}{\insertbiblabel}
\setbeamertemplate{bibliography entry article}{}
\setbeamertemplate{bibliography entry title}{}
\setbeamertemplate{bibliography entry location}{}
\setbeamertemplate{bibliography entry note}{}
\setbeamertemplate{bibliography entry year}{}
\setbeamertemplate{caption}[numbered]

% ---------------------------------------------------------------------------------------------------% 
% Title, author, date, etc.
% ---------------------------------------------------------------------------------------------------% 
\title{\huge Are Neural Click Models Pointwise IPS Rankers?}
\author{Philipp Hager\inst{1} \and Maarten de Rijke\inst{1} \and Onno Zoeter\inst{2}}
\institute[shortinst]{\inst{1} University of Amsterdam \inst{2} Booking.com}
\date[Sep. 2022]{September, 2022}
%%% Put the name of conference here.
	\def\conference{CONSEQUENCES+REVEAL Workshop at RecSys '22} 
 %%% Put your e-mail address here.
 	\def\yourEmail{p.k.hager@uva.nl}


% ---------------------------------------------------------------------------------------------------% 
% Contents
% ---------------------------------------------------------------------------------------------------% 
\begin{document}
\begin{frame}[t]
	\begin{columns}[t]
    % -----------------------------------------------------------
    % Start the first column
    % -----------------------------------------------------------
    \begin{column}{\onecolwid}
      % -----------------------------------------------------------
      % 1-1
      % -----------------------------------------------------------
    \begin{block}{Introduction}
	\baselineskip=.7\baselineskip

	Inverse-propensity scoring (IPS) and neural click models are two popular methods for learning rankers from position-biased click data.\\
	\vspace{1ex}
	Despite their prevalence, the two methodologies are rarely directly compared on equal footing.\\
	\vspace{1ex}
	We compare the theoretical differences of both approaches in the pointwise ranking setting and present an empirical comparison on semi-synthetic click data.

	\end{block}

	\vspace{1ex}

	% -----------------------------------------------------------
	% 1-2
	% -----------------------------------------------------------
	\begin{block}{Methods}
		\baselineskip=.7\baselineskip
	
		\textbf{User model:} Let $y_d$ be the probability of a document $d$ being relevant and $o_k$ the probability of observing a rank $k$, then users click only on items that are observed and relevant~\cite{Craswell2008Cascade}: $c_{d,k} = o_k \cdot y_d$.
		
		\vspace{1ex}
		
		\textbf{Neural click model:} Predicts biased user clicks. Document relevance $\hat{y}_d$ and position bias $\hat{o}_k$ are latent parameters inferred by minimizing binary cross-entropy between predicted and observed clicks~\cite{Yan2022TwoTowers}:
		\vspace{1ex}
		%
		\begin{equation*}
			\begin{split}
			\mathcal{L}_{\text{pbm}}(\hat{y}, \hat{o}) &= - \sum_{(d, k) \in D} c_{d,k} \cdot \log(\hat{y}_{d} \cdot \hat{o}_{k}) + (1 - c_{d,k}) \cdot \log(1 - \hat{y}_{d} \cdot \hat{o}_{k}).
			\end{split}
		\end{equation*}
		%

		\vspace{1ex}
		
		\textbf{Pointwise IPS:} Directly predicts document relevance $\hat{y}_d$ by weighting clicks inversely to the probability of being observed by the user~\cite{Saito2020PointwiseIPS}:
		\vspace{1ex}
		%
		\begin{equation*}
			\begin{split}
			\mathcal{L}_{\text{ips}}(\hat{y}, \hat{o}) = - \sum_{(d,k) \in D} \frac{c_{d,k}}{\hat{o}_k} \cdot \log(\hat{y}_{d}) + (1 - \frac{c_{d,k}}{\hat{o}_k}) \cdot \log(1 - \hat{y}_{d}).
			\end{split}
		\end{equation*}
		%

		\vspace{1ex}

		\begin{itemize}
			\item \textbf{Unbiased IPS}: Saito et al. show that the pointwise IPS estimator is unbiased when correctly estimating position bias~\cite{Saito2020PointwiseIPS}.
			\item \textbf{Click model inconsistency}: Oosterhuis shows that click models jointly inferring bias and relevance parameters are not always conistent estimators of document relevance~\cite{Oosterhuis2022ULTRLimits}.
			\item \textbf{Unbiased click model}: \alert{We show that the neural click model optimizes for unbiased document relevance when, similar to IPS, given access to the true position bias}: $\hat{y} = \frac{o \cdot y}{\hat{o}}$.
		\end{itemize}
	
	\end{block}

	\vspace{1ex}
	
	\begin{block}{The impact of position bias on loss}

		\begin{figure}[h]
			\includegraphics[width=1.\textwidth]{loss.pdf}
			%\caption{Visualizing the loss of the neural click model and pointwise IPS for a single document of relevance $y_d = 0.5$ under varying degrees of position bias.}
		\end{figure}
	
		\begin{itemize}
			\item The magnitude of the click model loss gets smaller with increasing position bias, since items at low positions will have a small click probability independent of their relevance.
			\item The IPS loss always converges to the same loss distribution as the number of clicks approaches infinity.
		\end{itemize}	
		
	\end{block}

\end{column}

    % -----------------------------------------------------------
    % Start the second column
    % -----------------------------------------------------------
    \begin{column}{\twocolwid}
	% -----------------------------------------------------------
	% 2-1
	% -----------------------------------------------------------
	\begin{block}{Experimental results}
		
	\begin{figure}[h]
		\includegraphics[width=1.\textwidth]{results}
		\caption{Test performance on three large-scale LTR datasets and one fully synthetic dataset after training on up to 100M simulated queries. All results are averaged over 10 independent runs, and we display a bootstrapped 95\% confidence interval.}
		\label{fig:results}
	\end{figure}
	
	\vskip1ex

	\begin{itemize}
		\item \textbf{IPS / PBM Naive}: Both approaches are equivalent when we naively do not compensating for position bias.
		\item \textbf{PBM - Estimated Bias}: A neural click model jointly estimating position bias and document relevance performs better than the naive baseline on YAHOO and MSLR-WEB30K.
		\item \textbf{PBM - True Bias}: A neural click model with access to the true position bias reduces variance and improves performance over the naive baseline on all datasets.
		\item \textbf{IPS - True Bias}: \alert{The IPS approach outperforms the neural click model significantly on Istella and Yahoo}.
	\end{itemize}

    \end{block}

	\vspace{2ex}

	\begin{block}{Is the neural click model biased?}

		\begin{figure}[h]
			\includegraphics[width=\textwidth]{loss_bias.pdf}
  			\label{fig:loss_bias}
		\end{figure}
		
		\vskip1ex
	
		\begin{itemize}
			\item Both approaches converge to the unbiased document relevance when computing the loss for each item separately (dotted lines).
			\item IPS converges to the average relevance of both documents, when optimizing the combined loss for both documents (solid line).
			\item \alert{The neural click model converges to a joint document relevance for both documents that is biased towards the item with the higher examination probability}.
		\end{itemize}
	
		\end{block}

\end{column}

    % -----------------------------------------------------------
    % Start the third column
    % -----------------------------------------------------------
    \begin{column}{\onecolwid}
	
	% -----------------------------------------------------------
	% 3-0
	% -----------------------------------------------------------
    \begin{block}{Experiments on neural click model bias}
   		\baselineskip=.7\baselineskip
	
		{\bf We run three additional experiments:}
		\begin{itemize}
			\item {\bf Independent features}: When documents share no features (one-hot encoded documents), the empirical performance of IPS and the neural click model is equivalent (Synthetic in Figure~\ref{fig:results}).
			\item {\bf Feature collisions}: Gradually forcing random documents to share feature vectors leads to stronger performance drop for the neural click model.
			\item {\bf Position bias recovery}: When simulating increasing levels of position bias, we find that IPS can recover from strong position bias, while the neural click model increasingly deteriorates in performance even if the true position bias is known.
		\end{itemize}

	\end{block}

	\vspace{2ex}

	% -----------------------------------------------------------
	% 3-1
	% -----------------------------------------------------------
	\begin{alertblock}{Takeways}
		\baselineskip=.7\baselineskip
	
		\begin{itemize}
			\item We show that both approaches optimize for unbiased document relevance if the true position bias is known and relevance is estimated separately per query-document pair.
			\item We find the neural click model to be affected by position bias when learning from shared, sometimes conflicting, features instead of estimating each document relevance separately.
		\end{itemize}

	\end{alertblock}


	\vspace{2ex}

	% -----------------------------------------------------------
	% 3-2
	% -----------------------------------------------------------
	\begin{block}{Selected References}
		\baselineskip=.7\baselineskip
		\bibliographystyle{acm}
		\bibliography{references}
	\end{block}

	\begin{block}{}
		\begin{figure}[h]
			\includegraphics[width=.3\textwidth]{qr}
			\caption*{Scan to read the paper}
		\end{figure}
	\end{block}

	\end{column}
\end{columns}
\end{frame}
\end{document}
